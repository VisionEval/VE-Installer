{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing package scan across a VisionEval repository\n",
    "\n",
    "Idea:\n",
    "\n",
    "- Pick the repository\n",
    "- Search across all files in the sources directory\n",
    "- Within each of framework, model, modules, and VEGUI, scan for all library and require statements in .R files\n",
    "- Compile list of all the locations where each package is used... store full path. \n",
    "- Aggregate to simple count of occurrences for each each package by framework, model, VE* module and VEGUI as columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np # for repeat\n",
    "import re \n",
    "import collections # for counting number of times a packages is used in a script\n",
    "\n",
    "# Pick repository version\n",
    "home_dir = str(Path.home())\n",
    "\n",
    "# Find location of VisionEval repository (or repositories). Assumes repo was cloned (i.e., includes .git)\n",
    "ve_dirs = []\n",
    "for path, dir, subdirs in os.walk(home_dir):\n",
    "    if re.search(r'VisionEval.+\\.git$', str(path)):\n",
    "            ve_dirs.append(path.rstrip('\\.git'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found repositories:\n",
      "C:\\Users\\Daniel.Flynn\\Documents\\git\\VisionEval\n",
      "C:\\Users\\Daniel.Flynn\\Documents\\git\\VisionEval-Dev\n",
      "Scanning first repository, C:\\Users\\Daniel.Flynn\\Documents\\git\\VisionEval\n"
     ]
    }
   ],
   "source": [
    "print(\"Found repositories:\", *ve_dirs, sep ='\\n')\n",
    "ve_dir = ve_dirs[0]\n",
    "print(\"Scanning first repository,\", ve_dir)\n",
    "# Export output to home for now\n",
    "export_dir = home_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = ve_dir.split(\"\\\\\")\n",
    "repo_name = repo_path[len(repo_path)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_packs = []\n",
    "\n",
    "for dir, subdirs, files in os.walk(ve_dir):\n",
    "    # Find .R files\n",
    "    for file in files:\n",
    "        if file.endswith(\".R\"):\n",
    "            # Read the file and scan for @import statements.\n",
    "            # Add encoding statement, otherwise fails for some files, likc CalculatePolicyVmt.R for some reason\n",
    "            found = re.findall('@import .+', open(os.path.join(dir, file), encoding=\"utf-8\").read())\n",
    "            found_list = [packs for segments in found for packs in segments.split()]\n",
    "            while '@import' in found_list: found_list.remove('@import')\n",
    "\n",
    "            found_from = re.findall('@importFrom .+', open(os.path.join(dir, file), encoding=\"utf-8\").read())\n",
    "            found_from_list = [packs for segments in found_from for packs in segments.split()]\n",
    "            found_from_list = found_from_list[:len(found_from_list)-1] # remove the function being imported\n",
    "            while '@importFrom' in found_from_list: found_from_list.remove('@importFrom')\n",
    "            \n",
    "            found_list.extend(found_from_list)\n",
    "            counter = collections.Counter(found_list)\n",
    "            if(len(counter)==0):\n",
    "                df = pd.DataFrame(data = {'dir': str(dir), 'file': str(file), 'package': [np.nan], 'count': [np.nan]})\n",
    "            else:\n",
    "                df = pd.DataFrame.from_dict(counter, orient='index').reset_index()\n",
    "                df.columns = ['package', 'count']\n",
    "                df[\"dir\"] = pd.Series(list(np.repeat([dir], len(df))))\n",
    "                df[\"file\"] = pd.Series(list(np.repeat([file], len(df))))\n",
    "            R_packs.append(df)\n",
    "\n",
    "R_packs = pd.concat(\n",
    "  R_packs, ignore_index=True, verify_integrity=True, sort = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting VisionEval_Dependency_Scan.csv to C:\\Users\\Daniel.Flynn\n"
     ]
    }
   ],
   "source": [
    "outfile = repo_name + '_Dependency_Scan.csv'\n",
    "print('Exporting ' + outfile + ' to ' + export_dir)\n",
    "\n",
    "R_packs.to_csv(os.path.join(export_dir, outfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = R_packs.groupby('package').agg({'count': 'sum'})\n",
    "\n",
    "results.sort_values('count', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting VisionEval_Dependency_Summary.csv to C:\\Users\\Daniel.Flynn\n"
     ]
    }
   ],
   "source": [
    "outfile = repo_name + '_Dependency_Summary.csv'\n",
    "print('Exporting ' + outfile + ' to ' + export_dir)\n",
    "\n",
    "results.to_csv(os.path.join(export_dir, outfile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
